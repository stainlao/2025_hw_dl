# Отчет
## Эксперимент 1: 
Модель быстро переобучается, т.к. имеет слишком простую архитектуру.
По графикам видно, что оптимальное количество эпох равно 4, т.к. валидационный AUC ROC после 
4 эпохи выходит на плато, а loss начинает расти, в то время как трэйн loss продолжает падать.

## Эксперимент 2: 
Благодаря увеличению в глубину и ширину, модель стала позже оверфититься и выбила больший скор на валидации. 
Лучшая эпоха по лосу - 7я, после нее идет переобучение. 
По графику ROC AUC на валидации лучшая эпоха - 10, график выходит на плато на 6-8 эпохе.

### Run summary:
eval_loss 0.22359

eval_rocauc 0.91371

## Эксперимент 3: 
BatchNorm должен ускорить сходимость модели. Так и произошло, модель снова стала сходиться уже к 4 эпохе.
Однако модель по графикам сошлась к модели из 1го эксперимента из-за skip-connection. 
Модель из эксперимента 2 лучше по валидационному ROC AUC.

Думаю, стоит убрать 1/2 из 3 skip connection, чтобы получить лучший скор, но в рамках эксперимента, 
т.к. дальше мы планируем использовать dropout и L2 в качестве регуляризации, а модель теперь снова быстро переообучается),
оставим как есть.

### Run summary:
eval_loss:0.25188374519348145
eval_rocauc:0.9082232117652892

## Эксперимент 4: 
При маленьком dropout p==0.01, 0.1 модель по графикам метрик почти не отличается от аналогичной модели без dropout. 
При p>=0.2 заметны изменения, графики Loss и AUC ROC ведут себя менее стабильно, можно найти лучшую по метрикам эпоху. 
При p==0.9 модель сильно падает по качеству, т.к. зануляется слишком много входных данных


## Эксперимент 5: 
При высоком wd==0.1 модель не учится совсем, loss на трэйне и валидации быстро выходят на плато, а AUC ROC падают.
Высокий lr==0.1 благодаря wd = 0.01, 0.001 учится и показывает неплохие результаты. Тут L2 нормализация сильно помогает.
В остальном же эти гиперпараметры не существенно изменяют графики аукроков.
Лучший результат показали wd=0.001, lr = 0.05, 

Val/ROCAUC = 0.91173, но превзойти архитектуру из 2го эксперимента не удалось.
